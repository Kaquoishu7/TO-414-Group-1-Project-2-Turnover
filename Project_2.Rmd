---
title: "Project_2"
author: "Aakash Bharat, Ishan Goel, Doyeon Kim, Raamiz Qureshi, Maegan DeSmet"
date: "2022-10-27"
output:
  html_document:
    toc: true
    theme: united
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Employee Turnover

### Summary

We have selected a data set that discusses the simulated employee turnover of company called TECHCO. This data set is both interesting and pertinent to a manager at TECHCO.

#### Why it's Interesting

Firstly, the data set has a lot of data points (over 34,000), so any model we create can be substantially trained. Secondly, the data set has 10 different variables that seem reasonable to consider for employee turnover. For example, knowing the gender, the distance from work, and at least one test score seems like interesting factors to consider. Lastly, the data set is available on Kaggle, so we'll have a way to test our final model in addition to the data we set aside for testing only in our RMD file.

#### Why it's a Business Problem

Employee turnover is an important factor in businesses. Hiring and training new employees in an investment, so if employee turnover is high, that investment begins to turn into a net loss. Retaining employees will allow firms to minimize hiring/training expenses and profit more from their employees' work. Furthermore, the more experience an employee has at the firm, the more valuably they'd be able to contribute; they have expertise and wisdom about working at the firm that new employees will not.

### Logistic Model

```{r}
turnover = read.csv("simulated_TECHCO_data.csv")
str(turnover)
summary(turnover)
```

```{r}
#turnover$turnover = as.factor(turnover$turnover)
turnover$turnover = ifelse(turnover$turnover == "Stayed", 0, 1)
turnover$gender = turnover$is_male
turnover$gender = ifelse(turnover$gender == 1,
                         "Male", "Female")
#turnover$is_male = as.factor(turnover$is_male)
turnover$is_male = NULL
turnover$emp_id = NULL
```

```{r}
logModelInitial =
  glm(formula = turnover ~ . + gender * similar_language,
               data = turnover,
               family = "binomial")
logModelInitial =
  step(logModelInitial, direction = "backward", trace = 0)
summary(logModelInitial)
```
# Layer 1 For Stack Model

## Libraries

```{r}
library(neuralnet)
library(class)
library(caret)
library(gmodels)
library(kernlab)
library(C50)
```

## Setup

```{r}
set.seed(0)
testIndices1 = sample(nrow(turnover), round(nrow(turnover) / 2))

# Use for L, SVM, and DT
trainReg1 = turnover[-testIndices1,]
testReg1 = turnover[testIndices1,]

trainRegUS1 = trainReg1
trainRegUS1$turnover = as.factor(trainRegUS1$turnover)

trainRegUS1 = upSample(trainRegUS1, trainRegUS1$turnover)
trainRegUS1$turnover = ifelse(trainRegUS1$turnover == "0", 0 , 1)

turnover_mm <- as.data.frame(model.matrix(~.-1,turnover))

normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

turnover_norm <- as.data.frame(lapply(turnover_mm, normalize))

# Use for ANN

trainNorm1 = turnover_norm[-testIndices1,]
testNorm1 = turnover_norm[testIndices1,]

# Use for KNN

trainNorm1KNN =turnover_norm[-testIndices1,
                          -match("turnover",names(turnover_norm))]
testNorm1KNN =turnover_norm[testIndices1,
                          -match("turnover",names(turnover_norm))]

trainRegLabels1 = turnover[-testIndices1,"turnover"]
testRegLabels1 = turnover[testIndices1,"turnover"]

trainNormLabels1 = turnover[-testIndices1,"turnover"]
testNormLabels1 = turnover[testIndices1, "turnover"]

```

## Logistic

```{r, cache = TRUE}
logModel1 = glm(formula = turnover ~ . + gender * .,
               data = trainReg1,
               family = "binomial")
logModel1 =
  step(logModel1, direction = "backward", trace = 0)
summary(logModel1)
```
```{r}
logPredictions1 = predict.glm(logModel1, newdata = testReg1,
                              type = "response")

# TODO: Tune the threshold
i = 0
myMax = 0
myThreshold = 0
while (i < 1) {
  val1 = ifelse(logPredictions1 > i, 1, 0) 
  val2 = as.data.frame(val1)
  val3 = confusionMatrix(as.factor(val2$val1),
                         as.factor(testRegLabels1))
  if (as.data.frame(val3$overall)$`val3$overall`[2] > myMax) {
    myMax = as.data.frame(val3$overall)$`val3$overall`[2]
    myThreshold = i
  }
  i = i + 0.001
}
```
```{r}
logPredictionsBinary1 = ifelse(logPredictions1 > 0.028, 1, 0)
logPredictionsDF1 = as.data.frame(logPredictionsBinary1)
CrossTable(x = testRegLabels1,
           y = logPredictionsDF1$logPredictionsBinary1,
           prop.chisq = FALSE)
confusionMatrix(as.factor(logPredictionsDF1$logPredictionsBinary1),
                as.factor(testRegLabels1))
```



## KNN
```{r, cache = TRUE}
library(class)
library(caret)
library(ggplot2)
turnover_knn_model <- knn (train = trainNorm1KNN,
                    test = testNorm1KNN,
                      cl = trainNormLabels1, k = 101)

summary(turnover_knn_model)
```
```{r}
library(gmodels)
CrossTable(x = testNormLabels1, y = turnover_knn_model, 
           prop.chisq=FALSE)
```

## ANN

```{r}

```


## SVM

```{r, cache = TRUE}
ctrl <- trainControl(method = "cv", 
                        number = 10, 
                        repeats = 10, 
                        selectionFunction = "oneSE")

grid <- expand.grid(C = c(0,0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2,5))

set.seed(0)
 
svm_model <- train(turnover ~., data = trainRegUS1, method = "svmLinear",
                 trControl=ctrl,
                 preProcess = c("center", "scale"),
                 tuneGrid = grid,
                 tuneLength = 10)


```


## DT

```{r}

```

