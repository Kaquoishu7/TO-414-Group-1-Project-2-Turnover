---
title: "Project_2"
author: "Aakash Bharat, Ishan Goel, Doyeon Kim, Raamiz Qureshi, Maegan DeSmet"
date: "2022-10-27"
output:
  html_document:
    toc: true
    theme: united
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Employee Turnover

### Summary

We have selected a data set that discusses the simulated employee turnover of company called TECHCO. This data set is both interesting and pertinent to a manager at TECHCO.

#### Why it's Interesting

Firstly, the data set has a lot of data points (over 34,000), so any model we create can be substantially trained. Secondly, the data set has 10 different variables that seem reasonable to consider for employee turnover. For example, knowing the gender, the distance from work, and at least one test score seems like interesting factors to consider. Lastly, the data set is available on Kaggle, so we'll have a way to test our final model in addition to the data we set aside for testing only in our RMD file.

#### Why it's a Business Problem

Employee turnover is an important factor in businesses. Hiring and training new employees in an investment, so if employee turnover is high, that investment begins to turn into a net loss. Retaining employees will allow firms to minimize hiring/training expenses and profit more from their employees' work. Furthermore, the more experience an employee has at the firm, the more valuably they'd be able to contribute; they have expertise and wisdom about working at the firm that new employees will not.

### Logistic Model

```{r}
turnover = read.csv("simulated_TECHCO_data.csv")
str(turnover)
summary(turnover)
```

```{r}
turnover$turnover = ifelse(turnover$turnover == "Stayed", 0, 1)
turnover$gender = turnover$is_male
turnover$gender = ifelse(turnover$gender == 1, "Male", "Female")
turnover$is_male = NULL
turnover$emp_id = NULL
```

# Layer 1 For Stack Model

## Libraries

```{r}
library(neuralnet)
library(class)
library(caret)
library(gmodels)
library(kernlab)
library(C50)
```

## Setup

```{r}
# Train model variables that are shared
control <- trainControl(method = "cv", number = 10,
                           selectionFunction = "oneSE")
```

```{r}
turnoverUS = turnover
turnoverUS$turnover = as.factor(turnoverUS$turnover)

turnoverUS = upSample(turnoverUS, turnoverUS$turnover)
turnoverUS$turnover = ifelse(turnoverUS$turnover == "0", 0 , 1)
turnoverUS$Class = NULL

turnoverTestLabels = turnover$turnover

```


## Logistic

```{r, cache = TRUE}
set.seed(300)
logModel1 <- train(as.factor(turnover) ~ . + gender * .,
                        method = "glm",
                        data = turnoverUS,
                        trControl = control,
                        family = "binomial")
logModel1
logPredictions1 <- predict(logModel1, newdata = turnover, type = "prob")

summary(logPredictions1)

pred2 <- ifelse(logPredictions1$`1` >= 0.6, 1, 0)

```
```{r}

CrossTable(x = pred2,
           y = turnoverTestLabels,
           prop.chisq = FALSE, prop.c = FALSE,
           prop.r = FALSE,
           dnn = c('Predicted Turnover', 'Actual Turnover'))

confusionMatrix(as.factor(pred2),
               as.factor(turnoverTestLabels), positive = "1")

```



## KNN
```{r, cache = TRUE}
library(class)
library(caret)
library(ggplot2)

set.seed(300)
grid <- expand.grid(.k = c(5, 15, 25, 99, 131))

KNNModel <- train(as.factor(turnover) ~ .,
                        method = "knn",
                        metric = "Kappa",
                        data = turnoverUS,
                        preProcess = c("center", "scale"),
                        trControl = control,
                        tuneGrid = grid)
KNNModel
```

```{r}
KNNPred <- predict(KNNModel, turnover)
table(KNNPred, turnoverTestLabels)

confusionMatrix(as.factor(KNNPred),
                as.factor(turnoverTestLabels))

CrossTable(KNNPred, turnoverTestLabels,
           prop.chisq = FALSE, prop.c = FALSE,
           prop.r = FALSE,
           dnn = c('Predicted Turnover', 'Actual Turnover'))
```

## ANN

```{r, cache = TRUE} 

set.seed(300)
grid <- expand.grid(.size = c(3, 4, 3), .decay = 0)

ANNModel1 <- train(as.factor(turnover) ~ .,
                   method = "nnet",
                   metric = "Kappa",
                   data = turnoverUS,
                   trControl = control,
                   tuneGrid = grid,
                   preProcess = c("center", "scale"))

ANNPred <- predict(ANNModel1, turnover)

```

```{r}
CrossTable(ANNPred, turnoverTestLabels,
           prop.chisq = FALSE, prop.c = FALSE,
           prop.r = FALSE,
           dnn = c('Predicted Turnover', 'Actual Turnover'))
confusionMatrix(as.factor(ANNPred), as.factor(turnoverTestLabels))
```

## SVM

```{r, cache = TRUE}
set.seed(300)

grid <- expand.grid(sigma = c(0.3, 0.5, 0.7, 0.9),
                    C = c(3, 5, 10, 15))

svm_model <- train(as.factor(turnover) ~.,
                  data = turnoverUS, method = "svmRadial",
                  tuneGrid = grid, 
                  trControl= control) 

svm_model

```

```{r}
SVMPred <- predict(svm_model, turnover)

table(SVMPred, turnoverTestLabels)

confusionMatrix(as.factor(SVMPred),
                as.factor(turnoverTestLabels))

CrossTable(SVMPred, turnoverTestLabels,
           prop.chisq = FALSE, prop.c = FALSE,
           prop.r = FALSE,
           dnn = c('Predicted Turnover', 'Actual Turnover'))
```


## DT

```{r, cache = TRUE}
set.seed(300)

grid <- expand.grid(.model = "tree",
                    .trials = c(1, 5, 10, 15, 20),
                    .winnow = "FALSE")

dt_model <- train(as.factor(turnover) ~.,
                  data = turnoverUS, method = "C5.0",
                  tuneGrid = grid, metric = "Kappa",
                  trControl= control)
dt_predict <- predict(dt_model, turnover)


```
```{r}

CrossTable(dt_predict, turnoverTestLabels,
           prop.chisq = FALSE, prop.c = FALSE,
           prop.r = FALSE,
           dnn = c('Predicted Turnover', 'Actual Turnover'))
confusionMatrix(as.factor(dt_predict),
                as.factor(turnoverTestLabels))

```

# Stack Model

## Combine Predictions

```{r}
turnover_pred <- data.frame(logPredictions1, KNNPred, ANNPred, SVMPred, dt_predict, turnoverTestLabels)

summary(turnover_pred)
str(turnover_pred)
```

## Seperate 70:30 test/train

```{r}
set.seed(12453)
test_set <- sample(nrow(turnover_pred), round(nrow(turnover_pred) / 10)*3)

turnover_stack_train <- turnover_pred[-test_set,]
turnover_stack_test <- turnover_pred[test_set, ]

str(turnover_stack_train)
str(turnover_stack_test)
```

## Stacked Decision Tree

```{r, cache = TRUE}
error_cast <- matrix(c(0,1,4,0), nrow=2)

turnover_stack_dt <- C5.0(as.factor(turnoverTestLabels) ~ .,
                          data = turnover_stack_train,
                          costs = error_cast)
```
```{r}
summary(turnover_stack_dt)

turnover_stack_model <- predict(turnover_stack_dt, turnover_stack_test)


CrossTable(turnover_stack_model,
           turnover_stack_test$turnoverTestLabels,
           prop.chisq = FALSE, prop.c = FALSE,
           prop.r = FALSE,
           dnn = c('Predicted Turnover', 'Actual Turnover'))
confusionMatrix(as.factor(turnover_stack_model),
                as.factor(turnover_stack_test$turnoverTestLabels))
```

#Report

Goal: Predict if an employee will leave or not so the company can work on retaining the employee and minimize their losses.
 
## Model Analyses
We built five individual models to try and predict employee turnover using the simulated data. We then combined the results to create a stacked model in hopes of improving our model and results.

### Logistic Model
For the logistic model, we used cross-validation with the train() function. We were specifically interested in how gender affects all the other variables, so we included that interaction term. Overall, the logistic model has an accuracy of  82.3% and a Kappa of 0.0359. The model also skews heavily toward negatives.

### KNN Model 
For the KNN model, we used cross-validation with the train() function. Overall, the KNN model with k= 5 has an accuracy of 96.9% and a Kappa of 0.4697. The model resulted in 1066 false positives, but 0 false negatives, showing that the model is skewed toward false positives. 

### ANN Model
For the ANN model, we once again used a 10-fold cross-validation with the train() function. When run on our data, the model had 62.3% accuracy with a 0.0205 Kappa. The kappa here was much worse than any of our other models. The accuracy was not the worst, but we had numerous models with over 90% accuracy that would be preferred to use over this. The model had 1% false negatives and 20% false positives. This model was, similar to the logistic model, skewed towards false positives.

### SVM Model
For the SVM model, we used 10-fold cross-validation with the train() function. Overall, the SVM model has an accuracy of 98.44% and a Kappa of 0.6413. The model resulted in 536 false positives, but 0 false negatives, showing that the model is skewed toward false positives. 

###Decision Tree
For the decision tree, we also used a 10-fold cross-validation with the train() function. The model was extremely accurate with 99.95% accuracy and .9828 Kappa. Furthermore, the model produced no false negatives and 4 false positives. In the context of employee turnover, this is encouraging since false negatives are worse than false positives. For these reasons, the decision tree proved to be our best preliminary model.

### Stacked Model
To improve our model, we created a stack model using the predictions from our previous five models as data points. The data frame had 17226 observations. This time we did not use cross-validation, but instead did a 70:30 test/train split. This was to ensure we did not overfit the data. We then used the c5.0 function to create a decision tree. We also used an error cost matrix to try and improve our false reports, primarily focusing on lowering false negatives as a false negative means wasting resources trying to keep employees who were not tending to leave. 
The model had 99.93% accuracy and a kappa of 0.9786. The Sensitivity was 0.99 and the false negatives were only 0.01. The false positives were even lower at 0.006.

## Recommendation
The data included 34,000 observations from 1,191 employees. 494 of those employees eventually left, leaving the company with a 41.48% turnover rate. The typical IT turnover rate is around 20%. Our research has shown that the average cost of turnover is roughly 30% of the employee's salary. Using average IT salaries in India (as the company uses data stimulated from an Indian IT company) we found that the average turnover cost per employee is $7,500 US dollars. For this company that makes the total turnover cost $3,705,000. 
If they were to use our stacked model, they would be able to correctly predict 98% of leaving employees (484) and then allocate resources to ensure they would stay. Assuming the best case and they manage to keep those 484 employees, they would save $3,630,000. This is possible since spending any amount of money under that savings would result in reduced overall costs and be better than the alternative, not spending money and losing 3.7 million. Even if the company is only able to keep enough employees to get down to the average 20% turnover rate, doing so would still save them $1,845,000. Thus we recommend that they use our model to predict who is leaving and works towards retaining those employees. 

